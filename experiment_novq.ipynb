{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1f892c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf53d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# CHANGE this for whatever GPU index you have\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"6\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5255d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tfkl = tf.keras.layers\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from aldi.modeling.layers import DownLevel, UpLevel\n",
    "from aldi.modeling.callbacks import ReconstructionPlotCallback\n",
    "from aldi.modeling.vq import Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1e2d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "(train_images, _), (test_images, _) = tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "train_images = train_images.astype(np.float32) / 255.\n",
    "test_images = test_images.astype(np.float32) / 255.\n",
    "\n",
    "train_data = tf.data.Dataset.from_tensor_slices(train_images).shuffle(50000).batch(batch_size, num_parallel_calls=tf.data.AUTOTUNE, drop_remainder=True)\n",
    "test_data = tf.data.Dataset.from_tensor_slices(test_images).batch(batch_size, num_parallel_calls=tf.data.AUTOTUNE).prefetch(tf.data.AUTOTUNE)\n",
    "train_data = train_data.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3623c53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# just looking at some images\n",
    "plt.figure(figsize=(15,15))\n",
    "for ind, img in enumerate(test_images[:64]):\n",
    "    plt.subplot(8, 8, ind+1)\n",
    "    plt.imshow(img)\n",
    "    plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2d6efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure they're normalized etc. :)\n",
    "a = plt.hist(test_images.reshape(-1), bins=255)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048d7fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder_stack(inputs, filters, strides, blocks_per_level):\n",
    "    inputs = tfkl.Conv2D(filters[0], 3, padding=\"same\")(inputs)\n",
    "    for level_ind, (level_filters, level_strides) in enumerate(zip(filters[1:], strides)):\n",
    "        inputs = DownLevel(2,\n",
    "                           blocks_per_level,\n",
    "                           level_filters,\n",
    "                           level_filters,\n",
    "                           3,\n",
    "                           level_strides,\n",
    "                           normalization=tfkl.BatchNormalization,\n",
    "                           name=\"down_level\" + str(level_ind))(inputs)\n",
    "        \n",
    "    return inputs\n",
    "\n",
    "\n",
    "def decoder_stack(inputs, filters, strides, blocks_per_level):\n",
    "    inputs = tfkl.Conv2D(filters[0], 3, padding=\"same\")(inputs)\n",
    "    for level_ind, (level_filters, level_strides) in enumerate(zip(filters[1:], strides)):\n",
    "        inputs = UpLevel(2,\n",
    "                         blocks_per_level,\n",
    "                         level_filters,\n",
    "                         level_filters,\n",
    "                         3,\n",
    "                         level_strides,\n",
    "                         normalization=tfkl.BatchNormalization,\n",
    "                         name=\"up_level\" + str(level_ind))(inputs)\n",
    "        \n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2208d0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "histories = []\n",
    "\n",
    "ds = [2, 4, 8, 16, 32, 64, 128, 256]\n",
    "for d in ds:\n",
    "    print(\"\\n\\n\\nRUNNING d={}\".format(d))\n",
    "    inp = tf.keras.Input((32, 32, 3))\n",
    "\n",
    "    blocks_per_level = 2\n",
    "    filters = [16, 32, 64, 128]\n",
    "    strides = [2, 2, 2]\n",
    "\n",
    "    encoder_final = encoder_stack(inp, filters, strides, blocks_per_level)\n",
    "    encoder_final = tfkl.Conv2D(d, 1, padding=\"same\")(encoder_final)\n",
    "\n",
    "    encoder = tf.keras.Model(inp, encoder_final, name=\"encoder\")\n",
    "\n",
    "    decoder_input = tf.keras.Input(encoder_final.shape[1:])\n",
    "    decoder_output = decoder_stack(decoder_input, list(reversed(filters)), list(reversed(strides)), blocks_per_level)\n",
    "    decoder_final = tfkl.Conv2D(3, 1,  padding=\"same\")(decoder_output)\n",
    "\n",
    "    decoder = tf.keras.Model(decoder_input, decoder_final, name=\"decoder\")\n",
    "\n",
    "\n",
    "    model = Autoencoder(inp, encoder, decoder, tf.keras.losses.MeanSquaredError(), name=\"autoencoder\")\n",
    "    model.summary(expand_nested=True)\n",
    "\n",
    "    # train_steps is wayyyy to high but it will run into early stopping anyways\n",
    "    train_steps = 500000\n",
    "    n_data = 50000\n",
    "    n_epochs = train_steps // (n_data // batch_size)\n",
    "    optimizer = tf.optimizers.Adam()\n",
    "\n",
    "    model.compile(optimizer=optimizer, jit_compile=True)\n",
    "\n",
    "\n",
    "    reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(patience=2, verbose=1, factor=0.5,\n",
    "                                                     min_delta=0.000001)\n",
    "    earlystop = tf.keras.callbacks.EarlyStopping(patience=6, verbose=1, restore_best_weights=True,\n",
    "                                                     min_delta=0.000001)\n",
    "\n",
    "    history = model.fit(train_data, validation_data=test_data, epochs=n_epochs, \n",
    "             callbacks=[ReconstructionPlotCallback(test_images[:16], 10, clip=True), reduce_lr, earlystop])\n",
    "    \n",
    "    models.append(model)\n",
    "    histories.append(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf1fc63",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_losses = []\n",
    "for model in models:\n",
    "    hmm = model.evaluate(test_data)\n",
    "    d_losses.append(hmm[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0710895",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(ds, d_losses, \"-*\")\n",
    "plt.xlabel(\"d\")\n",
    "plt.ylabel(\"Validation MSE\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2a80f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for history in histories:\n",
    "    for key in history:\n",
    "        vals = history[key]\n",
    "        plt.plot(vals)\n",
    "        plt.title(key)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ec6ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in models:\n",
    "    encoded = model.encoder.predict(test_data)\n",
    "    plt.hist(encoded.reshape(-1), bins=250)\n",
    "    plt.show()\n",
    "    enc_flat = encoded.reshape((-1, d))\n",
    "    plt.scatter(enc_flat[:, 0], enc_flat[:, 1], marker=\".\", alpha=0.1)\n",
    "    plt.gca().set_aspect(\"equal\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b589e533",
   "metadata": {},
   "outputs": [],
   "source": [
    "for d, model in zip(ds, models):\n",
    "    model.save(\"basic_d{}\".format(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54671f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "for d, history in zip(ds, histories):\n",
    "    with open(\"basic_d{}.pkl\".format(d), \"wb\") as file:\n",
    "        pickle.dump(history, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b147c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
